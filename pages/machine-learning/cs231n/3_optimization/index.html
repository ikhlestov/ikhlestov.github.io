<!DOCTYPE html>
<html prefix="
og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Optimization | Illarion&#8217;s Notes</title>
<link href="../../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../../../rss.xml">
<link rel="canonical" href="https://ikhlestov.github.io/pages/machine-learning/cs231n/3_optimization/">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    displayAlign: 'center', // Change this to 'center' to center equations.
});
</script><!--[if lt IE 9]><script src="../../../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Illarion Khlestov">
<meta property="og:site_name" content="Illarion's Notes">
<meta property="og:title" content="Optimization">
<meta property="og:url" content="https://ikhlestov.github.io/pages/machine-learning/cs231n/3_optimization/">
<meta property="og:description" content="Contents:

Introduction
Optimization
Strategy #3: Following the Gradient


Computing the gradient
Computing the gradient numerically with finite differences
Computing the gradient analytically with Ca">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2017-03-15T16:33:17Z">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-md static-top mb-4
navbar-dark bg-dark
"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="https://ikhlestov.github.io/">

            <span id="blog-title">Illarion&#8217;s Notes</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item">
<a href="../../../../" class="nav-link">About</a>
                </li>
<li class="nav-item">
<a href="../../../../posts/" class="nav-link">Blog&nbsp;Posts</a>
                </li>
<li class="nav-item">
<a href="../../../" class="nav-link">Pages</a>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <nav class="breadcrumbs"><ul class="breadcrumb">
<li class="breadcrumb-item"><a href="../../../">pages</a></li>
                <li class="breadcrumb-item"><a href="../../">machine-learning</a></li>
                <li class="breadcrumb-item"><a href="../">cs231n</a></li>
                <li class="breadcrumb-item active">3_optimization</li>
</ul></nav><div class="body-content">
        <!--Body content-->
        
<article class="post-text storypage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Optimization</a></h1>

        
    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<div class="contents topic" id="contents">
<p class="topic-title first">Contents:</p>
<ul class="simple">
<li><a class="reference internal" href="#introduction" id="id1">Introduction</a></li>
<li>
<a class="reference internal" href="#optimization" id="id2">Optimization</a><ul>
<li><a class="reference internal" href="#strategy-3-following-the-gradient" id="id3">Strategy #3: Following the&nbsp;Gradient</a></li>
</ul>
</li>
<li>
<a class="reference internal" href="#computing-the-gradient" id="id4">Computing the gradient</a><ul>
<li><a class="reference internal" href="#computing-the-gradient-numerically-with-finite-differences" id="id5">Computing the gradient numerically with finite&nbsp;differences</a></li>
<li><a class="reference internal" href="#computing-the-gradient-analytically-with-calculus" id="id6">Computing the gradient analytically with&nbsp;Calculus</a></li>
</ul>
</li>
<li><a class="reference internal" href="#gradient-descent" id="id7">Gradient&nbsp;Descent</a></li>
</ul>
</div>
<div class="section" id="introduction">
<h2><a class="toc-backref" href="#id1">Introduction</a></h2>
<p>Recall that the linear function had the form <span class="math">\(f(x_i, W) =  W x_i\)</span> and the SVM we developed was formulated&nbsp;as:</p>
<div class="math">
\begin{equation*}
L = \frac{1}{N} \sum_i \sum_{j\neq y_i} \left[ \max(0, f(x_i; W)_j - f(x_i; W)_{y_i} + 1) \right] + \alpha R(W)
\end{equation*}
</div>
<p>Optimization is the process of finding the set of parameters <span class="math">\(W\)</span> that minimize the loss&nbsp;function.</p>
<p><em>Non-differentiable loss functions.</em>
As a technical note, you can also see that the <em>kinks</em> in the loss function (due to the max operation) technically make the loss function non-differentiable because at these kinks the gradient is not defined.
However, the <a class="reference external" href="https://en.wikipedia.org/wiki/Subderivative">subgradient</a> still exists and is commonly used instead.
In this class will use the terms <em>subgradient</em> and <em>gradient</em>&nbsp;interchangeably.</p>
</div>
<div class="section" id="optimization">
<h2><a class="toc-backref" href="#id2">Optimization</a></h2>
<p>To reiterate, the loss function lets us quantify the quality of any particular set of weights <span class="math">\(W\)</span>.
The goal of optimization is to find <span class="math">\(W\)</span> that minimizes the loss&nbsp;function.</p>
<div class="section" id="strategy-3-following-the-gradient">
<h3><a class="toc-backref" href="#id3">Strategy #3: Following the&nbsp;Gradient</a></h3>
<p>It turns out that there is no need to randomly search for a good direction: we can compute the <em>best</em> direction along which we should change our weight vector that is mathematically guaranteed to be the direction of the steepest descend (at least in the limit as the step size goes towards zero).
This direction will be related to the <strong>gradient</strong> of the loss&nbsp;function.</p>
<p>In one-dimensional functions, the slope is the instantaneous rate of change of the function at any point you might be interested in.
The gradient is a generalization of slope for functions that donâ€™t take a single number but a vector of numbers.
Additionally, the gradient is just a vector of slopes (more commonly referred to as <strong>derivatives</strong>) for each dimension in the input space.
The mathematical expression for the derivative of a 1-D function with respect its input&nbsp;is:</p>
<div class="math">
\begin{equation*}
\frac{df(x)}{dx} = \lim_{h\ \to 0} \frac{f(x + h) - f(x)}{h}
\end{equation*}
</div>
<p>When the functions of interest take a vector of numbers instead of a single number, we call the derivatives <strong>partial derivatives</strong>,
and the gradient is simply the <strong>vector of partial derivatives</strong> in each&nbsp;dimension.</p>
</div>
</div>
<div class="section" id="computing-the-gradient">
<h2><a class="toc-backref" href="#id4">Computing the&nbsp;gradient</a></h2>
<p>There are two ways to compute the gradient: A slow, approximate but easy way (<strong>numerical gradient</strong>), and a fast, exact but more error-prone way that requires calculus (<strong>analytic gradient</strong>).</p>
<div class="section" id="computing-the-gradient-numerically-with-finite-differences">
<h3><a class="toc-backref" href="#id5">Computing the gradient numerically with finite&nbsp;differences</a></h3>
<p>This means iterates over all dimensions one by one, makes a small change <tt class="docutils literal">h</tt> along that dimension and calculates the partial derivative of the loss function along that dimension by seeing how much the function changed. The variable <tt class="docutils literal">grad</tt> holds the full gradient in the&nbsp;end.</p>
<p>Note that in the mathematical formulation the gradient is defined in the limit as <span class="math">\(h\)</span> goes towards zero, but in practice it is often sufficient to use a very small value (such as 1e-5).
Ideally, you want to use the smallest step size that does not lead to numerical issues.
Additionally, in practice it often works better to compute the numeric gradient using the <strong>centered difference formula</strong> (<a class="reference external" href="https://en.wikipedia.org/wiki/Numerical_differentiation">wiki</a>):
<span class="math">\([f(x+h) - f(x-h)] / 2 h\)</span>.</p>
<p><strong>Update in negative gradient direction.</strong> After computing a gradient update should be done in negative&nbsp;direction.</p>
<p><strong>Effect of step size.</strong> The gradient tells us the direction in which the function has the steepest rate of increase, but it does not tell us how far along this direction we should step.
As we will see later in the course, choosing the step size (also called the <strong>learning rate</strong>) will become one of the most important hyperparameter settings in training a neural&nbsp;network.</p>
<p><strong>A problem of efficiency.</strong>
You may have noticed that evaluating the numerical gradient has complexity linear in the number of parameters.
In our example we had 30730 parameters in total and therefore had to perform 30,731 evaluations of the loss function to evaluate the gradient and to perform only a single parameter update.
This problem only gets worse, since modern Neural Networks can easily have tens of millions of&nbsp;parameters.</p>
</div>
<div class="section" id="computing-the-gradient-analytically-with-calculus">
<h3><a class="toc-backref" href="#id6">Computing the gradient analytically with&nbsp;Calculus</a></h3>
<p>The numerical gradient is very simple to compute using the finite difference approximation, but the downside is that it is approximate (since we have to pick a small value of <em>h</em>, while the true gradient is defined as the limit as <em>h</em> goes to zero), and that it is very computationally expensive to compute.
The second way to compute the gradient is analytically using Calculus, which allows us to derive a direct formula for the gradient (no approximations) that is also very fast to compute.
However, unlike the numerical gradient it can be more error prone to implement, which is why in practice it is very common to compute the analytic gradient and compare it to the numerical gradient to check the correctness of your implementation.
This is called a <strong>gradient check</strong>.</p>
<p>Lets use the example of the SVM loss function for a single&nbsp;datapoint:</p>
<div class="math">
\begin{equation*}
L_i = \sum_{j\neq y_i} \left[ \max(0, w_j^Tx_i - w_{y_i}^Tx_i + \Delta) \right]
\end{equation*}
</div>
<p>We can differentiate the function with respect to the weights. For example, taking the gradient with respect to <span class="math">\(w_{y_i}\)</span> we&nbsp;obtain:</p>
<div class="math">
\begin{equation*}
\nabla_{w_{y_i}} L_i = - \left( \sum_{j\neq y_i} \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta &gt; 0) \right) x_i
\end{equation*}
</div>
<p>where <span class="math">\(\mathbb{1}\)</span> is the indicator function that is one if the condition inside is true or zero otherwise.
While the expression may look scary when it is written out, when youâ€™re implementing this in code youâ€™d simply count the number of classes that didnâ€™t meet the desired margin (and hence contributed to the loss function) and then the data vector <span class="math">\(x_i\)</span> scaled by this number is the gradient.
Notice that this is the gradient only with respect to the row of <span class="math">\(W\)</span> that corresponds to the correct class. For the other rows where <span class="math">\(j \neq y_i\)</span> the gradient&nbsp;is:</p>
<div class="math">
\begin{equation*}
\nabla_{w_j} L_i = \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta &gt; 0) x_i
\end{equation*}
</div>
<p>Once you derive the expression for the gradient it is straight-forward to implement the expressions and use them to perform the gradient&nbsp;update.</p>
</div>
</div>
<div class="section" id="gradient-descent">
<h2><a class="toc-backref" href="#id7">Gradient&nbsp;Descent</a></h2>
<p>Now that we can compute the gradient of the loss function, the procedure of repeatedly evaluating the gradient and then performing a parameter update is called <strong>Gradient Descent</strong>.
Its <strong>vanilla</strong> version looks as&nbsp;follows:</p>
<pre class="code python"><a name="rest_code_0796da7a19724ce7874c368f69a63ff5-1"></a><span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
<a name="rest_code_0796da7a19724ce7874c368f69a63ff5-2"></a>    <span class="n">weights_grad</span> <span class="o">=</span> <span class="n">evaluate_gradient</span><span class="p">(</span><span class="n">loss_fun</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
<a name="rest_code_0796da7a19724ce7874c368f69a63ff5-3"></a>    <span class="n">weights</span> <span class="o">+=</span> <span class="o">-</span> <span class="n">step_size</span> <span class="o">*</span> <span class="n">weights_grad</span> <span class="c1"># perform parameter update</span>
</pre>
<p><strong>Mini-batch gradient descent.</strong>
The training data can have on order of millions of examples.
Hence, it seems wasteful to compute the full loss function over the entire training set in order to perform only a single parameter update.
A very common approach to addressing this challenge is to compute the gradient over <strong>batches</strong> of the training data.
The reason this works well is that the examples in the training data are&nbsp;correlated.</p>
<p>The extreme case of this is a setting where the mini-batch contains only a single example.
This process is called <strong>Stochastic Gradient Descent</strong> (SGD) (or also sometimes <strong>on-line</strong> gradient&nbsp;descent).</p>
<div class="figure">
<img alt="http://cs231n.github.io/assets/dataflow.jpeg" src="http://cs231n.github.io/assets/dataflow.jpeg"><p class="caption">Summary of the informational flow. During the forward pass the score function computes class scores, stored in vector <strong>f</strong>. The loss function contains two components: The data loss computes the compatibility between the scores <strong>f</strong> and the labels <strong>y</strong>. The regularization loss is only a function of the weights. During Gradient Descent, we compute the gradient on the weights (and optionally on data if we wish) and use them to perform a parameter update during Gradient&nbsp;Descent.</p>
</div>
</div>
</div>
    </div>
    
</article><!--End of body content--><footer id="footer">
            Contents Â© 2019         <a href="mailto:ikhlestov@gmail.com">Illarion Khlestov</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>          <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script></footer>
</div>
</div>

        <script src="../../../../assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-92406723-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>