<!DOCTYPE html>
<html prefix="
og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>ML Bookmarks | Illarion&#8217;s Notes</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../../rss.xml">
<link rel="canonical" href="https://ikhlestov.github.io/pages/machine-learning/ml-bookmarks/">
<link rel="icon" href="../../../favicon.ico" sizes="16x16">
<link rel="icon" href="../../../favicon.png" sizes="128x128">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    displayAlign: 'center', // Change this to 'center' to center equations.
});
</script><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Illarion Khlestov">
<meta property="og:site_name" content="Illarion's Notes">
<meta property="og:title" content="ML Bookmarks">
<meta property="og:url" content="https://ikhlestov.github.io/pages/machine-learning/ml-bookmarks/">
<meta property="og:description" content="Contents

RNN, seq2seq and all related
CNNs
LightWeight CNNs


Special Nets
One Shot Learning
Reinforcement Learning
Build Neural Nets with another Neural Nets
Generative Networks
Other Topics


Optim">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2016-10-11T14:59:07Z">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-md static-top mb-4
navbar-dark bg-dark
"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="https://ikhlestov.github.io/">

            <span id="blog-title">Illarion&#8217;s Notes</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item">
<a href="../../../" class="nav-link">About</a>
                </li>
<li class="nav-item">
<a href="../../../posts/" class="nav-link">Blog&nbsp;Posts</a>
                </li>
<li class="nav-item">
<a href="../../" class="nav-link">Pages</a>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <nav class="breadcrumbs"><ul class="breadcrumb">
<li class="breadcrumb-item"><a href="../../">pages</a></li>
                <li class="breadcrumb-item"><a href="../">machine-learning</a></li>
                <li class="breadcrumb-item active">ml-bookmarks</li>
</ul></nav><div class="body-content">
        <!--Body content-->
        
<article class="post-text storypage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">ML&nbsp;Bookmarks</a></h1>

        
    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<div class="contents topic" id="contents">
<p class="topic-title first">Contents</p>
<ul class="simple">
<li><a class="reference internal" href="#rnn-seq2seq-and-all-related" id="id1">RNN, seq2seq and all&nbsp;related</a></li>
<li>
<a class="reference internal" href="#cnns" id="id2">CNNs</a><ul>
<li><a class="reference internal" href="#lightweight-cnns" id="id3">LightWeight&nbsp;CNNs</a></li>
</ul>
</li>
<li>
<a class="reference internal" href="#special-nets" id="id4">Special Nets</a><ul>
<li><a class="reference internal" href="#one-shot-learning" id="id5">One Shot&nbsp;Learning</a></li>
<li><a class="reference internal" href="#reinforcement-learning" id="id6">Reinforcement&nbsp;Learning</a></li>
<li><a class="reference internal" href="#build-neural-nets-with-another-neural-nets" id="id7">Build Neural Nets with another Neural&nbsp;Nets</a></li>
<li><a class="reference internal" href="#generative-networks" id="id8">Generative&nbsp;Networks</a></li>
<li><a class="reference internal" href="#other-topics" id="id9">Other&nbsp;Topics</a></li>
</ul>
</li>
<li>
<a class="reference internal" href="#optimization-techniques" id="id10">Optimization Techniques</a><ul>
<li><a class="reference internal" href="#papers-regarding-efficient-backprop-and-neural-networks-training" id="id11">Papers regarding efficient backprop and neural networks&nbsp;training</a></li>
</ul>
</li>
<li>
<a class="reference internal" href="#additional-resources" id="id12">Additional Resources</a><ul>
<li><a class="reference internal" href="#benchmarks" id="id13">Benchmarks</a></li>
<li><a class="reference internal" href="#datasets" id="id14">Datasets</a></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="rnn-seq2seq-and-all-related">
<h2><a class="toc-backref" href="#id1">RNN, seq2seq and all&nbsp;related</a></h2>
<ul class="simple">
<li>
<a class="reference external" href="https://arxiv.org/pdf/1511.04868v4.pdf">A Neural Transducer</a> Net than can generate predicition as more inputs arrives, without attention&nbsp;mechanism.</li>
<li>
<a class="reference external" href="http://distill.pub/2016/augmented-rnns/">Attention and Augmented Recurrent Neural Networks</a> Explanation of various RNNs complex&nbsp;architectures.</li>
<li>
<a class="reference external" href="https://arxiv.org/pdf/1610.03017v1.pdf">Fully Character-Level Neural Machine Translation without Explicit Segmentation</a>  model that maps a source character sequence to a target character sequence without any segmentation. (CNN + highway +&nbsp;biGRU)</li>
<li>
<a class="reference external" href="https://arxiv.org/pdf/1610.09513v1.pdf">Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences</a> LSTMs with additional time gate controlled by time step. This gate allow update <em>cell value</em> and <em>hidden output</em> only during an <em>&#8220;open&#8221;</em>&nbsp;phase.</li>
<li><a class="reference external" href="https://arxiv.org/pdf/1611.01724v1.pdf">Search Results Words or Characters? Fine-grained Gating for Reading&nbsp;Comprehension</a></li>
</ul>
</div>
<div class="section" id="cnns">
<h2><a class="toc-backref" href="#id2">CNNs</a></h2>
<ul class="simple">
<li>
<a class="reference external" href="http://www.lrec-conf.org/proceedings/lrec2016/pdf/103_Paper.pdf">Punctuation Prediction for Unsegmented Transcript Based on Word Vector</a> CNN for inserting punctuation to the&nbsp;text.</li>
<li><a class="reference external" href="https://arxiv.org/pdf/1611.05552v4.pdf">DelugeNets: Deep Networks with Massive and Flexible Cross-layer Information&nbsp;Inflows</a></li>
<li>
<a class="reference external" href="https://arxiv.org/pdf/1610.02391.pdf">Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</a> (<a class="reference external" href="https://github.com/ramprs/grad-cam">git repo</a>)</li>
<li><a class="reference external" href="https://arxiv.org/abs/1611.10012">Speed/accuracy trade-offs for modern convolutional object&nbsp;detectors</a></li>
</ul>
<div class="section" id="lightweight-cnns">
<h3><a class="toc-backref" href="#id3">LightWeight&nbsp;CNNs</a></h3>
<ul class="simple">
<li><a class="reference external" href="https://arxiv.org/abs/1602.07360">SqueezeNet</a></li>
<li><a class="reference external" href="https://arxiv.org/abs/1704.04861">MobileNet</a></li>
<li><a class="reference external" href="https://arxiv.org/abs/1707.01083">ShuffleNet</a></li>
</ul>
</div>
</div>
<div class="section" id="special-nets">
<h2><a class="toc-backref" href="#id4">Special&nbsp;Nets</a></h2>
<div class="section" id="one-shot-learning">
<h3><a class="toc-backref" href="#id5">One Shot&nbsp;Learning</a></h3>
<ul class="simple">
<li>
<a class="reference external" href="https://arxiv.org/pdf/1606.04080v1.pdf">Matching Networks for One Shot Learning</a> - one shot learning from Google Deep Mind for image&nbsp;net</li>
<li><a class="reference external" href="https://arxiv.org/pdf/1612.04844v1.pdf">The More You Know: Using Knowledge Graphs for Image&nbsp;Classification</a></li>
<li><a class="reference external" href="https://arxiv.org/pdf/1703.05175.pdf">Prototypical Networks for Few-shot&nbsp;Learning</a></li>
</ul>
</div>
<div class="section" id="reinforcement-learning">
<h3><a class="toc-backref" href="#id6">Reinforcement&nbsp;Learning</a></h3>
<ul class="simple">
<li>
<a class="reference external" href="https://arxiv.org/pdf/1606.04671.pdf">Progressive Neural Networks</a>  progressive networks approach immune to forgetting and can leverage prior knowledge via lateral connections to previously learned&nbsp;features.</li>
<li>
<a class="reference external" href="https://arxiv.org/pdf/1609.00150v1.pdf">Reward Augmented Maximum Likelihood for Neural Structured Prediction</a> (<a class="reference external" href="https://drive.google.com/file/d/0B3Rdm_P3VbRDVUQ4SVBRYW82dU0/view">Short Summary</a>)This paper presents a simple and computationally efficient approach to incorporate task reward into a  maximum likelihood framework. We establish a connection between the log-likelihood and regularized expected reward objectives, showing that at a zero temperature, they are approximately equivalent in  the vicinity of the  optimal&nbsp;solution.</li>
</ul>
</div>
<div class="section" id="build-neural-nets-with-another-neural-nets">
<h3><a class="toc-backref" href="#id7">Build Neural Nets with another Neural&nbsp;Nets</a></h3>
<ul class="simple">
<li>
<a class="reference external" href="https://arxiv.org/pdf/1609.09106v1.pdf">HYPER NETWORKS</a> This work explores hypernetworks:  an approach of using a small network, also known as a hypernetwork, to generate the weights for a larger&nbsp;network.</li>
<li>
<a class="reference external" href="https://arxiv.org/pdf/1607.01097v1.pdf">AdaNet: Adaptive Structural Learning of Artificial Neural Networks</a>  Our approach simultaneously and adaptively learns both the structure of the network as well as its&nbsp;weights.</li>
<li>
<a class="reference external" href="https://arxiv.org/pdf/1511.08130v2.pdf">A Roadmap towards Machine Intelligence</a>   In this paper, some fundamental properties that intelligent machines should have were proposed, focusing in particular on <em>communication</em> and <em>learning</em>.</li>
<li>
<a class="reference external" href="https://openreview.net/pdf?id=r1Ue8Hcxg">Neural Architecture Search with Reinforcement Learning</a> - broad grid search for availbale models architectures with LSTM. As result we receive new conv-net architecture and new RNN&nbsp;node.</li>
</ul>
</div>
<div class="section" id="generative-networks">
<h3><a class="toc-backref" href="#id8">Generative&nbsp;Networks</a></h3>
<ul class="simple">
<li><a class="reference external" href="https://arxiv.org/abs/1709.01620">Deep Learning Techniques for Music Generation - A&nbsp;Survey</a></li>
<li><a class="reference external" href="https://arxiv.org/pdf/1701.00160v1.pdf">NIPS 2016 Tutorial: Generative Adversarial&nbsp;Network</a></li>
</ul>
</div>
<div class="section" id="other-topics">
<h3><a class="toc-backref" href="#id9">Other&nbsp;Topics</a></h3>
<ul class="simple">
<li>
<a class="reference external" href="http://people.idsia.ch/~rupesh/very_deep_learning/">Highway Networks</a> - list of papers, code,&nbsp;etc.</li>
<li>Gumbel-Softmax at Categorical Variational Autoencoders - <a class="reference external" href="http://blog.evjang.com/2016/11/tutorial-categorical-variational.html">blog post</a>. Categorical Reparameterization with Gumbel-Softmax <a class="reference external" href="https://arxiv.org/pdf/1611.01144.pdf">original&nbsp;paper</a>
</li>
<li><a class="reference external" href="https://arxiv.org/pdf/1608.06048.pdf">Survey of resampling techniques for improving classification performance in unbalanced&nbsp;datasets</a></li>
<li><a class="reference external" href="https://arxiv.org/abs/1611.10012">Speed/accuracy trade-offs for modern convolutional object&nbsp;detectors</a></li>
</ul>
</div>
</div>
<div class="section" id="optimization-techniques">
<h2><a class="toc-backref" href="#id10">Optimization&nbsp;Techniques</a></h2>
<ul class="simple">
<li><a class="reference external" href="https://arxiv.org/pdf/1409.2329v5.pdf">RECURRENT NEURAL NETWORK&nbsp;REGULARIZATION</a></li>
<li><a class="reference external" href="http://arxiv.org/pdf/1603.05118.pdf">Recurrent Dropout without Memory&nbsp;Loss</a></li>
<li><a class="reference external" href="http://r2rt.com/styles-of-truncated-backpropagation.html">Styles of Truncated&nbsp;Backpropagation</a></li>
<li><a class="reference external" href="https://arxiv.org/pdf/1502.03167v3.pdf">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate&nbsp;Shift</a></li>
<li>
<a class="reference external" href="http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html">Hyperparameter optimization for Neural Networks</a> - example of many optimization approaches from NeuPy&nbsp;library.</li>
</ul>
<div class="section" id="papers-regarding-efficient-backprop-and-neural-networks-training">
<h3><a class="toc-backref" href="#id11">Papers regarding efficient backprop and neural networks&nbsp;training</a></h3>
<ul class="simple">
<li><a class="reference external" href="http://distill.pub/2017/momentum/">Why Momentum Really&nbsp;Works</a></li>
<li><a class="reference external" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2012/01/tricks-2012.pdf">Stochastic Gradient Descent Tricks(Leon&nbsp;Bottou)</a></li>
<li><a class="reference external" href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf">Efficient BackProb(Yann&nbsp;LeCun)</a></li>
<li><a class="reference external" href="https://arxiv.org/pdf/1206.5533v2.pdf">Practical Recommendations for Gradient-Based Training of Deep Architectures(Yoshua&nbsp;Bengio)</a></li>
<li><a class="reference external" href="https://arxiv.org/pdf/1412.6550.pdf">FitNets: Hints for Thin Deep&nbsp;Nets</a></li>
<li>
<a class="reference external" href="https://arxiv.org/pdf/1706.04859.pdf">Sobolev Training for Neural Networks</a> - training network with respect to optimize function&nbsp;derivatives.</li>
<li><a class="reference external" href="https://arxiv.org/pdf/1606.04474.pdf">Set parameter for one network from another(Learning to learn by gradient descent by gradient&nbsp;descent)</a></li>
<li>
<a class="reference external" href="https://arxiv.org/abs/1705.08292">The Marginal Value of Adaptive Gradient Methods in Machine Learning</a> - explanation why SGD can be better than Adam or other&nbsp;methods</li>
</ul>
</div>
</div>
<div class="section" id="additional-resources">
<h2><a class="toc-backref" href="#id12">Additional&nbsp;Resources</a></h2>
<ul class="simple">
<li>
<a class="reference external" href="http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf">A Few Useful Things to Know about Machine Learning</a> from cs231n&nbsp;course.</li>
</ul>
<div class="section" id="benchmarks">
<h3><a class="toc-backref" href="#id13">Benchmarks</a></h3>
<ul class="simple">
<li>
<a class="reference external" href="https://github.com/baidu-research/DeepBench">DeepBench</a> Benchmarking Deep Learning operations on different&nbsp;hardware</li>
</ul>
</div>
<div class="section" id="datasets">
<h3><a class="toc-backref" href="#id14">Datasets</a></h3>
<ul class="simple">
<li>
<a class="reference external" href="https://engineering.purdue.edu/elab/eVDS/">e-Lab Video Data Set(s)</a> Objects Tracking&nbsp;Dataset</li>
</ul>
</div>
</div>
</div>
    </div>
    
</article><!--End of body content--><footer id="footer">
            Contents © 2019         <a href="mailto:ikhlestov@gmail.com">Illarion Khlestov</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>          <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script></footer>
</div>
</div>

        <script src="../../../assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-92406723-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>