<!DOCTYPE html>
<html prefix="
og: http://ogp.me/ns#
article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>ML Bookmarks | Illarion Khlestov Blog</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../../rss.xml">
<link rel="canonical" href="https://ikhlestov.github.io/pages/machine-learning/ml-bookmarks/">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    displayAlign: 'center', // Change this to 'center' to center equations.
});
</script><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Illarion Khlestov">
<meta property="og:site_name" content="Illarion Khlestov Blog">
<meta property="og:title" content="ML Bookmarks">
<meta property="og:url" content="https://ikhlestov.github.io/pages/machine-learning/ml-bookmarks/">
<meta property="og:description" content="This is the list of some useful papers or resources with short explanation

Build Neural Nets with another Neural Nets

HYPER NETWORKS This work explores hypernetworks:  an approach of using a small n">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2016-10-11T14:59:07Z">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ikhlestov.github.io/">

                <span id="blog-title">Illarion Khlestov Blog</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../../../">Blog</a>
                </li>
<li>
<a href="../../">Pages</a>
                </li>
<li>
<a href="../../../listings/">Listings</a>
                </li>
<li>
<a href="../../../archive.html">Archive</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<li>
    <a href="index.rst" id="sourcelink">Source</a>
    </li>
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
<article class="post-text storypage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">ML Bookmarks</a></h1>

        
    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<p>This is the list of some useful papers or resources with short explanation</p>
<div class="section" id="build-neural-nets-with-another-neural-nets">
<h2>Build Neural Nets with another Neural Nets</h2>
<ul class="simple">
<li>
<a class="reference external" href="https://arxiv.org/pdf/1609.09106v1.pdf">HYPER NETWORKS</a> This work explores hypernetworks:  an approach of using a small network, also known as a hypernetwork, to generate the weights for a larger network.</li>
<li>
<a class="reference external" href="https://arxiv.org/pdf/1607.01097v1.pdf">AdaNet: Adaptive Structural Learning of Artificial Neural Networks</a>  Our approach simultaneously and adaptively learns both the structure of the network as well as its weights.</li>
<li>
<a class="reference external" href="https://arxiv.org/pdf/1511.08130v2.pdf">A Roadmap towards Machine Intelligence</a>   In this paper, some fundamental properties that intelligent machines should have were proposed, focusing in particular on <em>communication</em> and <em>learning</em>.</li>
<li>
<a class="reference external" href="https://openreview.net/pdf?id=r1Ue8Hcxg">Neural Architecture Search with Reinforcement Learning</a> - broad grid search for availbale models architectures with LSTM. As result we receive new conv-net architecture and new RNN node.</li>
</ul>
</div>
<div class="section" id="rnn-seq2seq-and-all-related">
<h2>RNN, seq2seq and all related</h2>
<ul class="simple">
<li>
<a class="reference external" href="https://arxiv.org/pdf/1511.04868v4.pdf">A Neural Transducer</a> Net than can generate predicition as more inputs arrives, without attention mechanism.</li>
<li>
<a class="reference external" href="http://distill.pub/2016/augmented-rnns/">Attention and Augmented Recurrent Neural Networks</a> Explanation of various RNNs complex architectures.</li>
<li>
<a class="reference external" href="https://arxiv.org/pdf/1610.03017v1.pdf">Fully Character-Level Neural Machine Translation without Explicit Segmentation</a>  model that maps a source character sequence to a target character sequence without any segmentation. (CNN + highway + biGRU)</li>
<li>
<a class="reference external" href="https://arxiv.org/pdf/1610.09513v1.pdf">Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences</a> LSTMs with additional time gate controlled by time step. This gate allow update <em>cell value</em> and <em>hidden output</em> only during an <em>"open"</em> phase.</li>
<li><a class="reference external" href="https://arxiv.org/pdf/1611.01724v1.pdf">Search Results Words or Characters? Fine-grained Gating for Reading Comprehension</a></li>
</ul>
</div>
<div class="section" id="cnns">
<h2>CNNs</h2>
<ul class="simple">
<li>
<a class="reference external" href="http://www.lrec-conf.org/proceedings/lrec2016/pdf/103_Paper.pdf">Punctuation Prediction for Unsegmented Transcript Based on Word Vector</a> CNN for inserting punctuation to the text.</li>
<li><a class="reference external" href="https://arxiv.org/pdf/1611.05552v4.pdf">DelugeNets: Deep Networks with Massive and Flexible Cross-layer Information Inflows</a></li>
</ul>
</div>
<div class="section" id="reinforcement-learning">
<h2>Reinforcement Learning</h2>
<ul class="simple">
<li>
<a class="reference external" href="https://arxiv.org/pdf/1606.04671.pdf">Progressive Neural Networks</a>  progressive networks approach immune to forgetting and can leverage prior knowledge via lateral connections to previously learned features.</li>
<li>
<a class="reference external" href="https://arxiv.org/pdf/1609.00150v1.pdf">Reward Augmented Maximum Likelihood for Neural Structured Prediction</a> (<a class="reference external" href="https://drive.google.com/file/d/0B3Rdm_P3VbRDVUQ4SVBRYW82dU0/view">Short Summary</a>)This paper presents a simple and computationally efficient approach to incorporate task reward into a  maximum likelihood framework. We establish a connection between the log-likelihood and regularized expected reward objectives, showing that at a zero temperature, they are approximately equivalent in  the vicinity of the  optimal solution.</li>
</ul>
</div>
<div class="section" id="optimization-techniques">
<h2>Optimization Techniques</h2>
<ul class="simple">
<li><a class="reference external" href="https://arxiv.org/pdf/1409.2329v5.pdf">RECURRENT NEURAL NETWORK REGULARIZATION</a></li>
<li><a class="reference external" href="http://arxiv.org/pdf/1603.05118.pdf">Recurrent Dropout without Memory Loss</a></li>
<li><a class="reference external" href="http://r2rt.com/styles-of-truncated-backpropagation.html">Styles of Truncated Backpropagation</a></li>
<li><a class="reference external" href="https://arxiv.org/pdf/1502.03167v3.pdf">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></li>
</ul>
</div>
<div class="section" id="other-topics">
<h2>Other Topics</h2>
<ul class="simple">
<li>
<a class="reference external" href="http://people.idsia.ch/~rupesh/very_deep_learning/">Highway Networks</a> - list of papers, code, etc.</li>
<li><a class="reference external" href="https://arxiv.org/pdf/1606.04474.pdf">Set parameter for one network from another(Learning to learn by gradient descent by gradient descent)</a></li>
<li><a class="reference external" href="https://arxiv.org/pdf/1701.00160v1.pdf">NIPS 2016 Tutorial: Generative Adversarial Network</a></li>
<li>Gumbel-Softmax at Categorical Variational Autoencoders - <a class="reference external" href="http://blog.evjang.com/2016/11/tutorial-categorical-variational.html">blog post</a>. Categorical Reparameterization with Gumbel-Softmax <a class="reference external" href="https://arxiv.org/pdf/1611.01144.pdf">original paper</a>
</li>
<li>
<a class="reference external" href="http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf">A Few Useful Things to Know about Machine Learning</a> from cs231n course.</li>
</ul>
</div>
<div class="section" id="papers-regardding-efficient-backprop-and-neural-networks-training">
<h2>Papers regardding efficient backprop and neural networks training</h2>
<ul class="simple">
<li><a class="reference external" href="http://distill.pub/2017/momentum/">Why Momentum Really Works</a></li>
<li><a class="reference external" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2012/01/tricks-2012.pdf">Stochastic Gradient Descent Tricks(Leon Bottou)</a></li>
<li><a class="reference external" href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf">Efficient BackProb(Yann LeCun)</a></li>
<li><a class="reference external" href="https://arxiv.org/pdf/1206.5533v2.pdf">Practical Recommendations for Gradient-Based Training of Deep Architectures(Yoshua Bengio)</a></li>
<li><a class="reference external" href="https://arxiv.org/pdf/1412.6550.pdf">FitNets: Hints for Thin Deep Nets</a></li>
</ul>
</div>
<div class="section" id="one-shot-learning">
<h2>One Shot Learning</h2>
<ul class="simple">
<li>
<a class="reference external" href="https://arxiv.org/pdf/1606.04080v1.pdf">Matching Networks for One Shot Learning</a> - one shot learning from Google Deep Mind for image net</li>
<li><a class="reference external" href="https://arxiv.org/pdf/1612.04844v1.pdf">The More You Know: Using Knowledge Graphs for Image Classification</a></li>
</ul>
</div>
<div class="section" id="benchmarks">
<h2>Benchmarks</h2>
<ul class="simple">
<li>
<a class="reference external" href="https://github.com/baidu-research/DeepBench">DeepBench</a> Benchmarking Deep Learning operations on different hardware</li>
</ul>
</div>
</div>
    </div>
    
</article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents Â© 2017         <a href="mailto:ikhlestov@gmail.com">Illarion Khlestov</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>          <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script></footer>
</div>
</div>

            <script src="../../../assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-92406723-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>
